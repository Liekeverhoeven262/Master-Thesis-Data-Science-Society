{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liekeverhoeven262/Master-Thesis-Data-Science-Society/blob/main/Final_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r2q6Eu1mkQ5",
        "outputId": "7d0e585e-c6a9-4a32-957b-756adb897741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri0T9ehYnV98"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Construct the path to the file in Google Drive\n",
        "personal_data_path = '/content/drive/My Drive/Master Thesis/FINAL_personal_data_compact3without.xlsx'\n",
        "thermal_data_path = '/content/drive/My Drive/Master Thesis/FINAL_scaled_features_df_max.xlsx'\n",
        "\n",
        "# Load the dataset\n",
        "personal_data_df = pd.read_excel(personal_data_path)\n",
        "thermal_data_df = pd.read_excel(thermal_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFl8VCZknWAw"
      },
      "outputs": [],
      "source": [
        "data = pd.merge(thermal_data_df, personal_data_df, on='ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLfTonLonWGa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import recall_score\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxetyJBanWJL"
      },
      "outputs": [],
      "source": [
        "# Define features and target\n",
        "features = data.drop(columns=['ID', 'Cluster', 'Sum2'])\n",
        "target = data['Sum2']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to handle imbalanced dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfuX7XFRnWMw"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_smote = scaler.fit_transform(X_train_smote)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6vfaGFvnmDx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Data voorbereiding\n",
        "X = np.array(X_train_smote)\n",
        "y = np.array(y_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9PI07kYEbmF",
        "outputId": "aac33c03-f694-4bb3-b2d8-8e311e3567e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.3.3)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.4.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras\n",
        "\n",
        "from scikeras.wrappers import KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbr6ZHCWBwPi",
        "outputId": "ee971de0-b14d-447e-c9c3-d440a3b65ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.12.2-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.0/258.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.10.1\n",
            "    Uninstalling imbalanced-learn-0.10.1:\n",
            "      Successfully uninstalled imbalanced-learn-0.10.1\n",
            "Successfully installed imbalanced-learn-0.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall scikit-learn -y\n",
        "!pip uninstall imbalanced-learn -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9LHHLbnBwTe",
        "outputId": "ad23d398-b327-4abd-e5ed-7179d23465e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: scikit-learn 1.4.2\n",
            "Uninstalling scikit-learn-1.4.2:\n",
            "  Successfully uninstalled scikit-learn-1.4.2\n",
            "Found existing installation: imbalanced-learn 0.7.0\n",
            "Uninstalling imbalanced-learn-0.7.0:\n",
            "  Successfully uninstalled imbalanced-learn-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn\n",
        "!pip install -U imbalanced-learn\n",
        "!pip install -U scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTjz_mcjESxE",
        "outputId": "a54128ab-ca3c-4258-f297-6adad6897889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Collecting imbalanced-learn\n",
            "  Using cached imbalanced_learn-0.12.2-py3-none-any.whl (257 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.8.0\n",
            "    Uninstalling imbalanced-learn-0.8.0:\n",
            "      Successfully uninstalled imbalanced-learn-0.8.0\n",
            "Successfully installed imbalanced-learn-0.12.2\n",
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.3.3)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.4.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFJkb-I2Ebox"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import recall_score, classification_report, precision_recall_curve, auc\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu3HjjwQLasq"
      },
      "outputs": [],
      "source": [
        "def create_model(learning_rate=0.01, optimizer='adam'):\n",
        "    model = Sequential([\n",
        "        Input(shape=(X_train.shape[1],)),\n",
        "        Dense(64, activation='relu'),  # Standaard aantal neuronen\n",
        "        Dropout(0.2),  # Standaard dropout rate\n",
        "        Dense(32, activation='relu'),  # Standaard halvering van neuronen in de tweede laag\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    if optimizer == 'adam':\n",
        "        opt = Adam(learning_rate=learning_rate)\n",
        "    else:\n",
        "        opt = SGD(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[tf.keras.metrics.Recall()])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7L3n9DrLawB"
      },
      "outputs": [],
      "source": [
        "# Data voorbereiding en SMOTE\n",
        "def prepare_data(X_train, y_train):\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_smote = scaler.fit_transform(X_train_smote)\n",
        "    return X_train_smote, y_train_smote, scaler\n",
        "\n",
        "model = KerasClassifier(model=create_model, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhu68UClLazN"
      },
      "outputs": [],
      "source": [
        "# Parameter grid voor GridSearchCV\n",
        "param_grid = {\n",
        "    'model__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
        "    'model__optimizer': ['adam', 'sgd'],\n",
        "    'batch_size': [16, 32, 64],\n",
        "    'epochs': [10, 50, 100]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-EYtZfyLa2B"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer, recall_score\n",
        "\n",
        "#focussen op de positieve klasse\n",
        "recall_scorer = make_scorer(recall_score, pos_label=1)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=recall_scorer, verbose=1)\n",
        "\n",
        "# Train en test splits\n",
        "features = data.drop(columns=['ID', 'Cluster', 'Sum2'])\n",
        "target = data['Sum2']\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Voorbereid data met SMOTE en normalisatie\n",
        "X_train_smote, y_train_smote, scaler = prepare_data(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GRupmheLa9t",
        "outputId": "5ef74700-2fc3-4884-b9a3-851cd5b10b85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
            "Best Recall: 0.928164 using {'batch_size': 16, 'epochs': 50, 'model__learning_rate': 0.01, 'model__optimizer': 'adam'}\n"
          ]
        }
      ],
      "source": [
        "# Uitvoeren van GridSearch\n",
        "grid_result = grid.fit(X_train_smote, y_train_smote)\n",
        "print(\"Best Recall: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSGg-zY5N7fX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273191ca-f805-46c2-c03b-464ba033251b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Low VVR       0.85      0.95      0.90        43\n",
            "    High VVR       0.87      0.65      0.74        20\n",
            "\n",
            "    accuracy                           0.86        63\n",
            "   macro avg       0.86      0.80      0.82        63\n",
            "weighted avg       0.86      0.86      0.85        63\n",
            "\n",
            "AUC-PR Score: 0.7602480096471037\n"
          ]
        }
      ],
      "source": [
        "# Evaluatie van het beste model op de testset\n",
        "X_test = scaler.transform(X_test)\n",
        "y_pred = grid_result.predict(X_test)\n",
        "y_pred_prob = grid_result.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Low VVR', 'High VVR']))\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "auc_pr = auc(recall, precision)\n",
        "print(\"AUC-PR Score:\", auc_pr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Including Cluster"
      ],
      "metadata": {
        "id": "6cXKogFQhM1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import recall_score, classification_report, precision_recall_curve, auc\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "features = data.drop(columns=['ID', 'Sum2'])\n",
        "target = data['Sum2']\n",
        "data_with_cluster = pd.get_dummies(features, columns=['Cluster'], prefix='Cluster')\n",
        "\n",
        "X_train_with_cluster, X_test_with_cluster, y_train_with_cluster, y_test_with_cluster = train_test_split(data_with_cluster, target, test_size=0.2, random_state=42)\n",
        "\n",
        "def prepare_data(X_train, y_train):\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_smote = scaler.fit_transform(X_train_smote)\n",
        "    return X_train_smote, y_train_smote, scaler\n",
        "\n",
        "def create_model_with_cluster(input_shape, learning_rate=0.01, optimizer='adam'):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_shape,)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    if optimizer == 'adam':\n",
        "        opt = Adam(learning_rate=learning_rate)\n",
        "    else:\n",
        "        opt = SGD(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[tf.keras.metrics.Recall()])\n",
        "    return model\n",
        "\n",
        "model_with_cluster = KerasClassifier(model=create_model_with_cluster, verbose=0, input_shape=X_train_with_cluster.shape[1])\n",
        "\n",
        "param_grid_with_cluster = {\n",
        "    'model__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
        "    'model__optimizer': ['adam', 'sgd'],\n",
        "    'batch_size': [16, 32, 64],\n",
        "    'epochs': [10, 50, 100]\n",
        "}\n",
        "\n",
        "grid_with_cluster = GridSearchCV(estimator=model_with_cluster, param_grid=param_grid_with_cluster, cv=5, scoring='recall', verbose=1)\n",
        "\n",
        "X_train_smote_with_cluster, y_train_smote_with_cluster, scaler_with_cluster = prepare_data(X_train_with_cluster, y_train_with_cluster)\n",
        "\n",
        "grid_result_with_cluster = grid_with_cluster.fit(X_train_smote_with_cluster, y_train_smote_with_cluster)\n",
        "print(\"Best Recall: %f using %s\" % (grid_result_with_cluster.best_score_, grid_result_with_cluster.best_params_))\n",
        "\n",
        "X_test_with_cluster = scaler_with_cluster.transform(X_test_with_cluster)\n",
        "y_pred_with_cluster = grid_result_with_cluster.predict(X_test_with_cluster)\n",
        "y_pred_prob_with_cluster = grid_result_with_cluster.predict_proba(X_test_with_cluster)[:, 1]\n",
        "\n",
        "print(\"Classification Report with Cluster:\")\n",
        "print(classification_report(y_test_with_cluster, y_pred_with_cluster, target_names=['Low VVR', 'High VVR']))\n",
        "\n",
        "precision_with_cluster, recall_with_cluster, _ = precision_recall_curve(y_test_with_cluster, y_pred_prob_with_cluster)\n",
        "auc_pr_with_cluster = auc(recall_with_cluster, precision_with_cluster)\n",
        "print(\"AUC-PR Score with Cluster:\", auc_pr_with_cluster)"
      ],
      "metadata": {
        "id": "oSjU0OL-4u9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca5ac32-4bd9-4b45-9991-449971d2bc63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f4d461acb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f4d461acb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Recall: 0.886275 using {'batch_size': 32, 'epochs': 50, 'model__learning_rate': 0.01, 'model__optimizer': 'adam'}\n",
            "Classification Report with Cluster:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Low VVR       0.78      0.84      0.81        43\n",
            "    High VVR       0.59      0.50      0.54        20\n",
            "\n",
            "    accuracy                           0.73        63\n",
            "   macro avg       0.69      0.67      0.67        63\n",
            "weighted avg       0.72      0.73      0.72        63\n",
            "\n",
            "AUC-PR Score with Cluster: 0.7064785939079614\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsuLMWl5ceILwfwh00I+am",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}