{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liekeverhoeven262/Master-Thesis-Data-Science-Society/blob/main/Final_Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftUgtLRFaeRk",
        "outputId": "10f00d6e-873b-4f6a-f0e4-f4d26bc0073c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puNl82tWbIGb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Construct the path to the file in Google Drive\n",
        "personal_data_path = '/content/drive/My Drive/Master Thesis/Data/FINAL_personal_data_compact3without.xlsx'\n",
        "thermal_data_path = '/content/drive/My Drive/Master Thesis/Data/FINAL_scaled_features_df_max.xlsx'\n",
        "\n",
        "# Load the dataset\n",
        "personal_data_df = pd.read_excel(personal_data_path)\n",
        "thermal_data_df = pd.read_excel(thermal_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXKnItPGbIKu",
        "outputId": "fe0b0c61-d8b4-4671-edd6-9e4bd3c7baa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'Cluster', 'Sum2', 'VVR1', 'VVR2'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(personal_data_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uf0IFvUfb-v",
        "outputId": "1d0bacef-8f8b-42f9-b193-dee815f7caf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of       ID  Cluster  Sum2  VVR1  VVR2\n",
            "0      5        2     0    13    12\n",
            "1      6        1     0     9    10\n",
            "2      7        1     1    12    14\n",
            "3      8        0     0    10    10\n",
            "4      9        0     0     9    10\n",
            "..   ...      ...   ...   ...   ...\n",
            "310  328        0     0    11    12\n",
            "311  329        0     0    11    10\n",
            "312  330        0     0    12    14\n",
            "313  331        1     0    15    16\n",
            "314  332        1     1    15    18\n",
            "\n",
            "[315 rows x 5 columns]>\n"
          ]
        }
      ],
      "source": [
        "print(personal_data_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e12CfC9bINm",
        "outputId": "1a4b9a49-7543-4fd2-aa41-10b84b7c8b67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'Left Cheek Sum', 'Left Cheek Variance',\n",
            "       'Left Cheek Standard Deviation', 'Left Cheek Maximum',\n",
            "       'Left Cheek Minimum', 'Left Cheek Median', 'Left Cheek Mean',\n",
            "       'Left Cheek Mean Absolute Change', 'Left Cheek Maximum Slope',\n",
            "       'Left Cheek Minimum Slope', 'Right Cheek Sum', 'Right Cheek Variance',\n",
            "       'Right Cheek Standard Deviation', 'Right Cheek Maximum',\n",
            "       'Right Cheek Minimum', 'Right Cheek Median', 'Right Cheek Mean',\n",
            "       'Right Cheek Mean Absolute Change', 'Right Cheek Maximum Slope',\n",
            "       'Right Cheek Minimum Slope', 'Below Nose Sum', 'Below Nose Variance',\n",
            "       'Below Nose Standard Deviation', 'Below Nose Maximum',\n",
            "       'Below Nose Minimum', 'Below Nose Median', 'Below Nose Mean',\n",
            "       'Below Nose Mean Absolute Change', 'Below Nose Maximum Slope',\n",
            "       'Below Nose Minimum Slope', 'Between Eyes Sum', 'Between Eyes Variance',\n",
            "       'Between Eyes Standard Deviation', 'Between Eyes Maximum',\n",
            "       'Between Eyes Minimum', 'Between Eyes Median', 'Between Eyes Mean',\n",
            "       'Between Eyes Mean Absolute Change', 'Between Eyes Maximum Slope',\n",
            "       'Between Eyes Minimum Slope', 'Chin Sum', 'Chin Variance',\n",
            "       'Chin Standard Deviation', 'Chin Maximum', 'Chin Minimum',\n",
            "       'Chin Median', 'Chin Mean', 'Chin Mean Absolute Change',\n",
            "       'Chin Maximum Slope', 'Chin Minimum Slope', 'Nose Sum', 'Nose Variance',\n",
            "       'Nose Standard Deviation', 'Nose Maximum', 'Nose Minimum',\n",
            "       'Nose Median', 'Nose Mean', 'Nose Mean Absolute Change',\n",
            "       'Nose Maximum Slope', 'Nose Minimum Slope'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(thermal_data_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMAWSvsbbIQO"
      },
      "outputs": [],
      "source": [
        "data = pd.merge(thermal_data_df, personal_data_df, on='ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg2aPvywcAI_",
        "outputId": "4bbca6b2-1143-46e2-bbf8-524bd11b1830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'Left Cheek Sum', 'Left Cheek Variance',\n",
            "       'Left Cheek Standard Deviation', 'Left Cheek Maximum',\n",
            "       'Left Cheek Minimum', 'Left Cheek Median', 'Left Cheek Mean',\n",
            "       'Left Cheek Mean Absolute Change', 'Left Cheek Maximum Slope',\n",
            "       'Left Cheek Minimum Slope', 'Right Cheek Sum', 'Right Cheek Variance',\n",
            "       'Right Cheek Standard Deviation', 'Right Cheek Maximum',\n",
            "       'Right Cheek Minimum', 'Right Cheek Median', 'Right Cheek Mean',\n",
            "       'Right Cheek Mean Absolute Change', 'Right Cheek Maximum Slope',\n",
            "       'Right Cheek Minimum Slope', 'Below Nose Sum', 'Below Nose Variance',\n",
            "       'Below Nose Standard Deviation', 'Below Nose Maximum',\n",
            "       'Below Nose Minimum', 'Below Nose Median', 'Below Nose Mean',\n",
            "       'Below Nose Mean Absolute Change', 'Below Nose Maximum Slope',\n",
            "       'Below Nose Minimum Slope', 'Between Eyes Sum', 'Between Eyes Variance',\n",
            "       'Between Eyes Standard Deviation', 'Between Eyes Maximum',\n",
            "       'Between Eyes Minimum', 'Between Eyes Median', 'Between Eyes Mean',\n",
            "       'Between Eyes Mean Absolute Change', 'Between Eyes Maximum Slope',\n",
            "       'Between Eyes Minimum Slope', 'Chin Sum', 'Chin Variance',\n",
            "       'Chin Standard Deviation', 'Chin Maximum', 'Chin Minimum',\n",
            "       'Chin Median', 'Chin Mean', 'Chin Mean Absolute Change',\n",
            "       'Chin Maximum Slope', 'Chin Minimum Slope', 'Nose Sum', 'Nose Variance',\n",
            "       'Nose Standard Deviation', 'Nose Maximum', 'Nose Minimum',\n",
            "       'Nose Median', 'Nose Mean', 'Nose Mean Absolute Change',\n",
            "       'Nose Maximum Slope', 'Nose Minimum Slope', 'Cluster', 'Sum2', 'VVR1',\n",
            "       'VVR2'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIo-IBW8cARW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOFx1818hKB4"
      },
      "outputs": [],
      "source": [
        "# Feature columns: thermal data and VVR1, VVR2\n",
        "features = data.loc[:, 'Left Cheek Sum':'Nose Minimum Slope'].columns.tolist()\n",
        "features.extend(['VVR1', 'VVR2'])\n",
        "\n",
        "# Target variable\n",
        "target = 'Sum2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce8R2cZRqi9f",
        "outputId": "440daf83-934d-4ed2-c78d-00355fb64543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Left Cheek Sum', 'Left Cheek Variance', 'Left Cheek Standard Deviation', 'Left Cheek Maximum', 'Left Cheek Minimum', 'Left Cheek Median', 'Left Cheek Mean', 'Left Cheek Mean Absolute Change', 'Left Cheek Maximum Slope', 'Left Cheek Minimum Slope', 'Right Cheek Sum', 'Right Cheek Variance', 'Right Cheek Standard Deviation', 'Right Cheek Maximum', 'Right Cheek Minimum', 'Right Cheek Median', 'Right Cheek Mean', 'Right Cheek Mean Absolute Change', 'Right Cheek Maximum Slope', 'Right Cheek Minimum Slope', 'Below Nose Sum', 'Below Nose Variance', 'Below Nose Standard Deviation', 'Below Nose Maximum', 'Below Nose Minimum', 'Below Nose Median', 'Below Nose Mean', 'Below Nose Mean Absolute Change', 'Below Nose Maximum Slope', 'Below Nose Minimum Slope', 'Between Eyes Sum', 'Between Eyes Variance', 'Between Eyes Standard Deviation', 'Between Eyes Maximum', 'Between Eyes Minimum', 'Between Eyes Median', 'Between Eyes Mean', 'Between Eyes Mean Absolute Change', 'Between Eyes Maximum Slope', 'Between Eyes Minimum Slope', 'Chin Sum', 'Chin Variance', 'Chin Standard Deviation', 'Chin Maximum', 'Chin Minimum', 'Chin Median', 'Chin Mean', 'Chin Mean Absolute Change', 'Chin Maximum Slope', 'Chin Minimum Slope', 'Nose Sum', 'Nose Variance', 'Nose Standard Deviation', 'Nose Maximum', 'Nose Minimum', 'Nose Median', 'Nose Mean', 'Nose Mean Absolute Change', 'Nose Maximum Slope', 'Nose Minimum Slope', 'VVR1', 'VVR2']\n"
          ]
        }
      ],
      "source": [
        "print(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGljFz5q_fE1",
        "outputId": "171e3c98-7564-4fc2-f9e1-d0bfd849c0a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum2\n",
            "0    168\n",
            "1    168\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE only on the training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Checking the balance of the classes after SMOTE\n",
        "print(pd.Series(y_train_smote).value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAeb12U6_fJ7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM7dCfuWeEcj"
      },
      "source": [
        "## Model 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [10, 15, 20, 25, None],\n",
        "    'min_samples_split': [2, 5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4, 6]\n",
        "}\n",
        "\n",
        "# Setup the GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Best parameters and best recall\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best recall:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_RQaHYnIwz7",
        "outputId": "6f182c0e-0be3-44e8-f898-eb523c3831fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Best recall: 0.8684491978609625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, recall_score, precision_score, average_precision_score\n",
        "\n",
        "# Setup the optimized Random Forest model using the best parameters from GridSearchCV\n",
        "optimized_rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model on the balanced training set\n",
        "optimized_rf.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Predict on the test data\n",
        "predictions_optimized = optimized_rf.predict(X_test)\n",
        "probabilities_optimized = optimized_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Optimized Model Evaluation:\")\n",
        "print(classification_report(y_test, predictions_optimized))\n",
        "\n",
        "# Calculate specific metrics\n",
        "precision = precision_score(y_test, predictions_optimized, pos_label=1)\n",
        "recall = recall_score(y_test, predictions_optimized, pos_label=1)\n",
        "auc_pr = average_precision_score(y_test, probabilities_optimized)\n",
        "print(f'Precision for High VVR: {precision}')\n",
        "print(f'Recall for High VVR: {recall}')\n",
        "print(f'AUC-PR for High VVR: {auc_pr}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJE9HZS5Iw5S",
        "outputId": "59ea76ad-1f0d-4c1f-8bd4-64851b40a987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Model Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90        43\n",
            "           1       0.87      0.65      0.74        20\n",
            "\n",
            "    accuracy                           0.86        63\n",
            "   macro avg       0.86      0.80      0.82        63\n",
            "weighted avg       0.86      0.86      0.85        63\n",
            "\n",
            "Precision for High VVR: 0.8666666666666667\n",
            "Recall for High VVR: 0.65\n",
            "AUC-PR for High VVR: 0.8084839130403649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With cluster"
      ],
      "metadata": {
        "id": "bXGtoJIn1gIE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U99ie3VxeC9o",
        "outputId": "3a5192a5-e456-45a8-947e-6ed524221228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'Left Cheek Sum', 'Left Cheek Variance',\n",
            "       'Left Cheek Standard Deviation', 'Left Cheek Maximum',\n",
            "       'Left Cheek Minimum', 'Left Cheek Median', 'Left Cheek Mean',\n",
            "       'Left Cheek Mean Absolute Change', 'Left Cheek Maximum Slope',\n",
            "       'Left Cheek Minimum Slope', 'Right Cheek Sum', 'Right Cheek Variance',\n",
            "       'Right Cheek Standard Deviation', 'Right Cheek Maximum',\n",
            "       'Right Cheek Minimum', 'Right Cheek Median', 'Right Cheek Mean',\n",
            "       'Right Cheek Mean Absolute Change', 'Right Cheek Maximum Slope',\n",
            "       'Right Cheek Minimum Slope', 'Below Nose Sum', 'Below Nose Variance',\n",
            "       'Below Nose Standard Deviation', 'Below Nose Maximum',\n",
            "       'Below Nose Minimum', 'Below Nose Median', 'Below Nose Mean',\n",
            "       'Below Nose Mean Absolute Change', 'Below Nose Maximum Slope',\n",
            "       'Below Nose Minimum Slope', 'Between Eyes Sum', 'Between Eyes Variance',\n",
            "       'Between Eyes Standard Deviation', 'Between Eyes Maximum',\n",
            "       'Between Eyes Minimum', 'Between Eyes Median', 'Between Eyes Mean',\n",
            "       'Between Eyes Mean Absolute Change', 'Between Eyes Maximum Slope',\n",
            "       'Between Eyes Minimum Slope', 'Chin Sum', 'Chin Variance',\n",
            "       'Chin Standard Deviation', 'Chin Maximum', 'Chin Minimum',\n",
            "       'Chin Median', 'Chin Mean', 'Chin Mean Absolute Change',\n",
            "       'Chin Maximum Slope', 'Chin Minimum Slope', 'Nose Sum', 'Nose Variance',\n",
            "       'Nose Standard Deviation', 'Nose Maximum', 'Nose Minimum',\n",
            "       'Nose Median', 'Nose Mean', 'Nose Mean Absolute Change',\n",
            "       'Nose Maximum Slope', 'Nose Minimum Slope', 'Sum2', 'VVR1', 'VVR2',\n",
            "       'Cluster_0', 'Cluster_1', 'Cluster_2'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# One-hot encode 'Cluster'\n",
        "data_with_cluster = pd.get_dummies(data, columns=['Cluster'], prefix='Cluster')\n",
        "\n",
        "# Check new columns\n",
        "print(data_with_cluster.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Include new cluster columns in the features list\n",
        "features_with_cluster = data_with_cluster.columns.difference(['ID', 'Sum2']).tolist()  # Exclude 'ID' and 'Sum2' from features\n",
        "\n",
        "# Define the target variable\n",
        "target_with_cluster = 'Sum2'"
      ],
      "metadata": {
        "id": "09GLgkE47BoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0zBf8QKeYjS"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and test sets\n",
        "X_train_with_cluster, X_test_with_cluster, y_train_with_cluster, y_test_with_cluster = train_test_split(\n",
        "    data_with_cluster[features_with_cluster], data_with_cluster[target_with_cluster], test_size=0.2, random_state=42)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE\n",
        "smote_with_cluster = SMOTE(random_state=42)\n",
        "X_train_smote_with_cluster, y_train_smote_with_cluster = smote_with_cluster.fit_resample(X_train_with_cluster, y_train_with_cluster)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "rf_with_cluster = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid_with_cluster = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [10, 15, 20, 25, None],\n",
        "    'min_samples_split': [2, 5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4, 6]\n",
        "}\n",
        "\n",
        "# Setup the GridSearchCV\n",
        "grid_search_with_cluster = GridSearchCV(estimator=rf_with_cluster, param_grid=param_grid_with_cluster, cv=5, scoring='recall', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search_with_cluster.fit(X_train_smote_with_cluster, y_train_smote_with_cluster)\n",
        "\n",
        "# Best parameters and best recall\n",
        "print(\"Best parameters including Cluster:\", grid_search_with_cluster.best_params_)\n",
        "print(\"Best recall including Cluster:\", grid_search_with_cluster.best_score_)"
      ],
      "metadata": {
        "id": "fKmDEIYF6tcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde8b0c7-9120-49f6-ca56-38eacc4a9031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters including Cluster: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
            "Best recall including Cluster: 0.8620320855614974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the optimized Random Forest model using the best parameters from GridSearchCV\n",
        "optimized_rf_with_cluster = RandomForestClassifier(\n",
        "    n_estimators=400,\n",
        "    max_depth=15,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model on the balanced training set\n",
        "optimized_rf_with_cluster.fit(X_train_smote_with_cluster, y_train_smote_with_cluster)\n",
        "\n",
        "# Predict on the test data\n",
        "predictions_optimized_with_cluster = optimized_rf_with_cluster.predict(X_test_with_cluster)\n",
        "probabilities_optimized_with_cluster = optimized_rf_with_cluster.predict_proba(X_test_with_cluster)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Optimized Model Evaluation with Cluster:\")\n",
        "print(classification_report(y_test_with_cluster, predictions_optimized_with_cluster))\n",
        "\n",
        "# Calculate specific metrics\n",
        "precision_with_cluster = precision_score(y_test_with_cluster, predictions_optimized_with_cluster, pos_label=1)\n",
        "recall_with_cluster = recall_score(y_test_with_cluster, predictions_optimized_with_cluster, pos_label=1)\n",
        "auc_pr_with_cluster = average_precision_score(y_test_with_cluster, probabilities_optimized_with_cluster)\n",
        "print(f'Precision for High VVR: {precision_with_cluster}')\n",
        "print(f'Recall for High VVR: {recall_with_cluster}')\n",
        "print(f'AUC-PR for High VVR: {auc_pr_with_cluster}')"
      ],
      "metadata": {
        "id": "fycjzv2p6tg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d14d3e-6d12-4aba-c80d-bc0e22920afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Model Evaluation with Cluster:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89        43\n",
            "           1       0.86      0.60      0.71        20\n",
            "\n",
            "    accuracy                           0.84        63\n",
            "   macro avg       0.85      0.78      0.80        63\n",
            "weighted avg       0.84      0.84      0.83        63\n",
            "\n",
            "Precision for High VVR: 0.8571428571428571\n",
            "Recall for High VVR: 0.6\n",
            "AUC-PR for High VVR: 0.8276022702934247\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlj+vZvGFWm0p5U1pA8KTT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}