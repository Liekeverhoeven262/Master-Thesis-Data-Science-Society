{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftUgtLRFaeRk",
        "outputId": "d7605dd8-5a40-4d0c-c19d-8868d85714c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puNl82tWbIGb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Construct the path to the file in Google Drive\n",
        "personal_data_path = '/content/drive/My Drive/Master Thesis/Data/FINAL_personal_data_compact3without.xlsx'\n",
        "thermal_data_path = '/content/drive/My Drive/Master Thesis/Data/FINAL_scaled_features_df_max.xlsx'\n",
        "\n",
        "# Load the dataset\n",
        "personal_data_df = pd.read_excel(personal_data_path)\n",
        "thermal_data_df = pd.read_excel(thermal_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXKnItPGbIKu",
        "outputId": "0d98be4a-e23b-4eb1-8029-21b1d0ca2245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'Cluster', 'Sum2', 'VVR1', 'VVR2'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(personal_data_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uf0IFvUfb-v",
        "outputId": "019dded2-d769-454f-b1d8-8116186270cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of       ID  Cluster  Sum2  VVR1  VVR2\n",
            "0      5        2     0    13    12\n",
            "1      6        1     0     9    10\n",
            "2      7        1     1    12    14\n",
            "3      8        0     0    10    10\n",
            "4      9        0     0     9    10\n",
            "..   ...      ...   ...   ...   ...\n",
            "310  328        0     0    11    12\n",
            "311  329        0     0    11    10\n",
            "312  330        0     0    12    14\n",
            "313  331        1     0    15    16\n",
            "314  332        1     1    15    18\n",
            "\n",
            "[315 rows x 5 columns]>\n"
          ]
        }
      ],
      "source": [
        "print(personal_data_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e12CfC9bINm",
        "outputId": "9070d406-449f-4339-d107-653d816c2c23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'Left Cheek Sum', 'Left Cheek Variance',\n",
            "       'Left Cheek Standard Deviation', 'Left Cheek Maximum',\n",
            "       'Left Cheek Minimum', 'Left Cheek Median', 'Left Cheek Mean',\n",
            "       'Left Cheek Mean Absolute Change', 'Left Cheek Maximum Slope',\n",
            "       'Left Cheek Minimum Slope', 'Right Cheek Sum', 'Right Cheek Variance',\n",
            "       'Right Cheek Standard Deviation', 'Right Cheek Maximum',\n",
            "       'Right Cheek Minimum', 'Right Cheek Median', 'Right Cheek Mean',\n",
            "       'Right Cheek Mean Absolute Change', 'Right Cheek Maximum Slope',\n",
            "       'Right Cheek Minimum Slope', 'Below Nose Sum', 'Below Nose Variance',\n",
            "       'Below Nose Standard Deviation', 'Below Nose Maximum',\n",
            "       'Below Nose Minimum', 'Below Nose Median', 'Below Nose Mean',\n",
            "       'Below Nose Mean Absolute Change', 'Below Nose Maximum Slope',\n",
            "       'Below Nose Minimum Slope', 'Between Eyes Sum', 'Between Eyes Variance',\n",
            "       'Between Eyes Standard Deviation', 'Between Eyes Maximum',\n",
            "       'Between Eyes Minimum', 'Between Eyes Median', 'Between Eyes Mean',\n",
            "       'Between Eyes Mean Absolute Change', 'Between Eyes Maximum Slope',\n",
            "       'Between Eyes Minimum Slope', 'Chin Sum', 'Chin Variance',\n",
            "       'Chin Standard Deviation', 'Chin Maximum', 'Chin Minimum',\n",
            "       'Chin Median', 'Chin Mean', 'Chin Mean Absolute Change',\n",
            "       'Chin Maximum Slope', 'Chin Minimum Slope', 'Nose Sum', 'Nose Variance',\n",
            "       'Nose Standard Deviation', 'Nose Maximum', 'Nose Minimum',\n",
            "       'Nose Median', 'Nose Mean', 'Nose Mean Absolute Change',\n",
            "       'Nose Maximum Slope', 'Nose Minimum Slope'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(thermal_data_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMAWSvsbbIQO"
      },
      "outputs": [],
      "source": [
        "data = pd.merge(thermal_data_df, personal_data_df, on='ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg2aPvywcAI_",
        "outputId": "5bb61e62-e16e-4bb5-b348-5c848848a5bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'Left Cheek Sum', 'Left Cheek Variance',\n",
            "       'Left Cheek Standard Deviation', 'Left Cheek Maximum',\n",
            "       'Left Cheek Minimum', 'Left Cheek Median', 'Left Cheek Mean',\n",
            "       'Left Cheek Mean Absolute Change', 'Left Cheek Maximum Slope',\n",
            "       'Left Cheek Minimum Slope', 'Right Cheek Sum', 'Right Cheek Variance',\n",
            "       'Right Cheek Standard Deviation', 'Right Cheek Maximum',\n",
            "       'Right Cheek Minimum', 'Right Cheek Median', 'Right Cheek Mean',\n",
            "       'Right Cheek Mean Absolute Change', 'Right Cheek Maximum Slope',\n",
            "       'Right Cheek Minimum Slope', 'Below Nose Sum', 'Below Nose Variance',\n",
            "       'Below Nose Standard Deviation', 'Below Nose Maximum',\n",
            "       'Below Nose Minimum', 'Below Nose Median', 'Below Nose Mean',\n",
            "       'Below Nose Mean Absolute Change', 'Below Nose Maximum Slope',\n",
            "       'Below Nose Minimum Slope', 'Between Eyes Sum', 'Between Eyes Variance',\n",
            "       'Between Eyes Standard Deviation', 'Between Eyes Maximum',\n",
            "       'Between Eyes Minimum', 'Between Eyes Median', 'Between Eyes Mean',\n",
            "       'Between Eyes Mean Absolute Change', 'Between Eyes Maximum Slope',\n",
            "       'Between Eyes Minimum Slope', 'Chin Sum', 'Chin Variance',\n",
            "       'Chin Standard Deviation', 'Chin Maximum', 'Chin Minimum',\n",
            "       'Chin Median', 'Chin Mean', 'Chin Mean Absolute Change',\n",
            "       'Chin Maximum Slope', 'Chin Minimum Slope', 'Nose Sum', 'Nose Variance',\n",
            "       'Nose Standard Deviation', 'Nose Maximum', 'Nose Minimum',\n",
            "       'Nose Median', 'Nose Mean', 'Nose Mean Absolute Change',\n",
            "       'Nose Maximum Slope', 'Nose Minimum Slope', 'Cluster', 'Sum2', 'VVR1',\n",
            "       'VVR2'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIo-IBW8cARW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, average_precision_score\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNPlOzT196M0"
      },
      "outputs": [],
      "source": [
        "features = ['Left Cheek Sum', 'Left Cheek Variance', 'Left Cheek Standard Deviation', 'Left Cheek Maximum',\n",
        "            'Left Cheek Minimum', 'Left Cheek Median', 'Left Cheek Mean', 'Left Cheek Mean Absolute Change',\n",
        "            'Left Cheek Maximum Slope', 'Left Cheek Minimum Slope', 'Right Cheek Sum', 'Right Cheek Variance',\n",
        "            'Right Cheek Standard Deviation', 'Right Cheek Maximum', 'Right Cheek Minimum', 'Right Cheek Median',\n",
        "            'Right Cheek Mean', 'Right Cheek Mean Absolute Change', 'Right Cheek Maximum Slope', 'Right Cheek Minimum Slope',\n",
        "            'Below Nose Sum', 'Below Nose Variance', 'Below Nose Standard Deviation', 'Below Nose Maximum',\n",
        "            'Below Nose Minimum', 'Below Nose Median', 'Below Nose Mean', 'Below Nose Mean Absolute Change',\n",
        "            'Below Nose Maximum Slope', 'Below Nose Minimum Slope', 'Between Eyes Sum', 'Between Eyes Variance',\n",
        "            'Between Eyes Standard Deviation', 'Between Eyes Maximum', 'Between Eyes Minimum', 'Between Eyes Median',\n",
        "            'Between Eyes Mean', 'Between Eyes Mean Absolute Change', 'Between Eyes Maximum Slope',\n",
        "            'Between Eyes Minimum Slope', 'Chin Sum', 'Chin Variance', 'Chin Standard Deviation', 'Chin Maximum',\n",
        "            'Chin Minimum', 'Chin Median', 'Chin Mean', 'Chin Mean Absolute Change', 'Chin Maximum Slope',\n",
        "            'Chin Minimum Slope', 'Nose Sum', 'Nose Variance', 'Nose Standard Deviation', 'Nose Maximum',\n",
        "            'Nose Minimum', 'Nose Median', 'Nose Mean', 'Nose Mean Absolute Change', 'Nose Maximum Slope',\n",
        "            'Nose Minimum Slope', 'VVR1', 'VVR2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlwPGvfirIZR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HMmvJ1m96Qk"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data['Sum2'], test_size=0.2, random_state=42)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "270h0wGY96TP",
        "outputId": "e0f1ae1e-4141-4102-cc33-fa9013a7ca50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 2304 candidates, totalling 11520 fits\n",
            "Best parameters: {'colsample_bytree': 0.75, 'gamma': 0, 'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 100, 'subsample': 0.75}\n",
            "Best recall: 0.8983957219251337\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the XGBoost model; note the inclusion of `eval_metric` to avoid warnings\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Create the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 500],\n",
        "    'max_depth': [3, 6, 9, 12],\n",
        "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
        "    'subsample': [0.5, 0.75, 1.0],\n",
        "    'colsample_bytree': [0.5, 0.75, 1.0],\n",
        "    'gamma': [0, 0.1, 0.5, 1]\n",
        "}\n",
        "\n",
        "# Setup the grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='recall', verbose=1)\n",
        "\n",
        "# Fit the grid search to the balanced training data\n",
        "grid_search.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best recall:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JyAakqLSSUJ",
        "outputId": "2613eeb9-6837-4438-8f6e-1d24b35f9eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90        43\n",
            "           1       0.82      0.70      0.76        20\n",
            "\n",
            "    accuracy                           0.86        63\n",
            "   macro avg       0.85      0.82      0.83        63\n",
            "weighted avg       0.85      0.86      0.85        63\n",
            "\n",
            "Precisie: 0.823529\n",
            "Recall: 0.70\n",
            "AUC-PR: 0.746753\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, average_precision_score, roc_auc_score\n",
        "\n",
        "# Setup the optimized XGBoost model using the best parameters from GridSearchCV\n",
        "optimized_xgb = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=9,\n",
        "    learning_rate=0.2,\n",
        "    subsample=0.75,\n",
        "    colsample_bytree=0.75,\n",
        "    gamma=0,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model on the balanced training set\n",
        "optimized_xgb.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Predict on the test data\n",
        "predictions_optimized = optimized_xgb.predict(X_test)\n",
        "probabilities_optimized = optimized_xgb.predict_proba(X_test)[:, 1]  # probabilities for the positive class\n",
        "\n",
        "# Evaluate the model using classification report\n",
        "print(\"XGBoost Model Classification Report:\")\n",
        "print(classification_report(y_test, predictions_optimized, digits=2))\n",
        "\n",
        "# Calculate specific metrics\n",
        "precision = precision_score(y_test, predictions_optimized, pos_label=1)\n",
        "recall = recall_score(y_test, predictions_optimized, pos_label=1)\n",
        "auc_pr = average_precision_score(y_test, probabilities_optimized)\n",
        "\n",
        "# Print specific metrics\n",
        "print(f'Precisie: {precision:.6f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'AUC-PR: {auc_pr:.6f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Cluster"
      ],
      "metadata": {
        "id": "CKC7Sf2B5XPD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWAwauDzSSYO"
      },
      "outputs": [],
      "source": [
        "features_with_cluster = ['Left Cheek Sum', 'Left Cheek Variance', 'Left Cheek Standard Deviation', 'Left Cheek Maximum',\n",
        "            'Left Cheek Minimum', 'Left Cheek Median', 'Left Cheek Mean', 'Left Cheek Mean Absolute Change',\n",
        "            'Left Cheek Maximum Slope', 'Left Cheek Minimum Slope', 'Right Cheek Sum', 'Right Cheek Variance',\n",
        "            'Right Cheek Standard Deviation', 'Right Cheek Maximum', 'Right Cheek Minimum', 'Right Cheek Median',\n",
        "            'Right Cheek Mean', 'Right Cheek Mean Absolute Change', 'Right Cheek Maximum Slope', 'Right Cheek Minimum Slope',\n",
        "            'Below Nose Sum', 'Below Nose Variance', 'Below Nose Standard Deviation', 'Below Nose Maximum',\n",
        "            'Below Nose Minimum', 'Below Nose Median', 'Below Nose Mean', 'Below Nose Mean Absolute Change',\n",
        "            'Below Nose Maximum Slope', 'Below Nose Minimum Slope', 'Between Eyes Sum', 'Between Eyes Variance',\n",
        "            'Between Eyes Standard Deviation', 'Between Eyes Maximum', 'Between Eyes Minimum', 'Between Eyes Median',\n",
        "            'Between Eyes Mean', 'Between Eyes Mean Absolute Change', 'Between Eyes Maximum Slope',\n",
        "            'Between Eyes Minimum Slope', 'Chin Sum', 'Chin Variance', 'Chin Standard Deviation', 'Chin Maximum',\n",
        "            'Chin Minimum', 'Chin Median', 'Chin Mean', 'Chin Mean Absolute Change', 'Chin Maximum Slope',\n",
        "            'Chin Minimum Slope', 'Nose Sum', 'Nose Variance', 'Nose Standard Deviation', 'Nose Maximum',\n",
        "            'Nose Minimum', 'Nose Median', 'Nose Mean', 'Nose Mean Absolute Change', 'Nose Maximum Slope',\n",
        "            'Nose Minimum Slope', 'VVR1', 'VVR2', 'Cluster']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr_-ooAfSScE",
        "outputId": "07269b4f-c9dd-45e7-e4d3-df2517b274fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'Left Cheek Sum', 'Left Cheek Variance',\n",
            "       'Left Cheek Standard Deviation', 'Left Cheek Maximum',\n",
            "       'Left Cheek Minimum', 'Left Cheek Median', 'Left Cheek Mean',\n",
            "       'Left Cheek Mean Absolute Change', 'Left Cheek Maximum Slope',\n",
            "       'Left Cheek Minimum Slope', 'Right Cheek Sum', 'Right Cheek Variance',\n",
            "       'Right Cheek Standard Deviation', 'Right Cheek Maximum',\n",
            "       'Right Cheek Minimum', 'Right Cheek Median', 'Right Cheek Mean',\n",
            "       'Right Cheek Mean Absolute Change', 'Right Cheek Maximum Slope',\n",
            "       'Right Cheek Minimum Slope', 'Below Nose Sum', 'Below Nose Variance',\n",
            "       'Below Nose Standard Deviation', 'Below Nose Maximum',\n",
            "       'Below Nose Minimum', 'Below Nose Median', 'Below Nose Mean',\n",
            "       'Below Nose Mean Absolute Change', 'Below Nose Maximum Slope',\n",
            "       'Below Nose Minimum Slope', 'Between Eyes Sum', 'Between Eyes Variance',\n",
            "       'Between Eyes Standard Deviation', 'Between Eyes Maximum',\n",
            "       'Between Eyes Minimum', 'Between Eyes Median', 'Between Eyes Mean',\n",
            "       'Between Eyes Mean Absolute Change', 'Between Eyes Maximum Slope',\n",
            "       'Between Eyes Minimum Slope', 'Chin Sum', 'Chin Variance',\n",
            "       'Chin Standard Deviation', 'Chin Maximum', 'Chin Minimum',\n",
            "       'Chin Median', 'Chin Mean', 'Chin Mean Absolute Change',\n",
            "       'Chin Maximum Slope', 'Chin Minimum Slope', 'Nose Sum', 'Nose Variance',\n",
            "       'Nose Standard Deviation', 'Nose Maximum', 'Nose Minimum',\n",
            "       'Nose Median', 'Nose Mean', 'Nose Mean Absolute Change',\n",
            "       'Nose Maximum Slope', 'Nose Minimum Slope', 'Sum2', 'VVR1', 'VVR2',\n",
            "       'Cluster_0', 'Cluster_1', 'Cluster_2'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# One-hot encode 'Cluster'\n",
        "data_with_cluster = pd.get_dummies(data, columns=['Cluster'], prefix='Cluster')\n",
        "\n",
        "# Check new columns\n",
        "print(data_with_cluster.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSBhWOVxSSfi"
      },
      "outputs": [],
      "source": [
        "# Include new cluster columns in the features list\n",
        "features_with_cluster = data_with_cluster.columns.difference(['ID', 'Sum2']).tolist()  # Exclude 'ID' and 'Sum2' from features\n",
        "\n",
        "# Define the target variable\n",
        "target_with_cluster = 'Sum2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouP_Ld7FN_gi"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and test sets\n",
        "X_train_with_cluster, X_test_with_cluster, y_train_with_cluster, y_test_with_cluster = train_test_split(\n",
        "    data_with_cluster[features_with_cluster], data_with_cluster[target_with_cluster], test_size=0.2, random_state=42)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE\n",
        "smote_with_cluster = SMOTE(random_state=42)\n",
        "X_train_smote_with_cluster, y_train_smote_with_cluster = smote_with_cluster.fit_resample(X_train_with_cluster, y_train_with_cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fid80OdKHwfZ",
        "outputId": "ccec9484-7845-4de7-a54d-c09a336ff697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 2304 candidates, totalling 11520 fits\n",
            "Best parameters: {'colsample_bytree': 0.75, 'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.75}\n",
            "Best recall: 0.8923351158645276\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the XGBoost model\n",
        "xgb_with_cluster = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Create the parameter grid\n",
        "param_grid_with_cluster = {\n",
        "    'n_estimators': [100, 200, 300, 500],\n",
        "    'max_depth': [3, 6, 9, 12],\n",
        "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
        "    'subsample': [0.5, 0.75, 1.0],\n",
        "    'colsample_bytree': [0.5, 0.75, 1.0],\n",
        "    'gamma': [0, 0.1, 0.5, 1]\n",
        "}\n",
        "\n",
        "# Setup the grid search with cross-validation\n",
        "grid_search_with_cluster = GridSearchCV(estimator=xgb_with_cluster, param_grid=param_grid_with_cluster, cv=5, scoring='recall', verbose=1)\n",
        "\n",
        "# Fit the grid search to the balanced training data\n",
        "grid_search_with_cluster.fit(X_train_smote_with_cluster, y_train_smote_with_cluster)\n",
        "\n",
        "# Print the best parameters and best recall\n",
        "print(\"Best parameters:\", grid_search_with_cluster.best_params_)\n",
        "print(\"Best recall:\", grid_search_with_cluster.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, average_precision_score, roc_auc_score\n",
        "\n",
        "# Setup the optimized XGBoost model using the best parameters from GridSearchCV\n",
        "optimized_xgb_with_cluster = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.2,\n",
        "    subsample=0.75,\n",
        "    colsample_bytree=0.75,\n",
        "    gamma=0.1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model on the balanced training set\n",
        "optimized_xgb_with_cluster.fit(X_train_smote_with_cluster, y_train_smote_with_cluster)\n",
        "\n",
        "# Predict on the test data\n",
        "predictions_optimized_with_cluster = optimized_xgb_with_cluster.predict(X_test_with_cluster)\n",
        "probabilities_optimized_with_cluster = optimized_xgb_with_cluster.predict_proba(X_test_with_cluster)[:, 1]  # probabilities for the positive class\n",
        "\n",
        "# Evaluate the model using classification report\n",
        "print(\"XGBoost Model Classification Report With Cluster:\")\n",
        "print(classification_report(y_test_with_cluster, predictions_optimized_with_cluster, digits=2))\n",
        "\n",
        "# Calculate specific metrics\n",
        "precision_with_cluster = precision_score(y_test_with_cluster, predictions_optimized_with_cluster, pos_label=1)\n",
        "recall_with_cluster = recall_score(y_test_with_cluster, predictions_optimized_with_cluster, pos_label=1)\n",
        "auc_pr_with_cluster = average_precision_score(y_test_with_cluster, probabilities_optimized_with_cluster)\n",
        "\n",
        "# Print specific metrics\n",
        "print(f'Precisie: {precision_with_cluster:.6f}')\n",
        "print(f'Recall: {recall_with_cluster:.2f}')\n",
        "print(f'AUC-PR: {auc_pr_with_cluster:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ2j7Q2w5Qtf",
        "outputId": "3703660c-36c2-498f-e741-c676b36d5e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model Classification Report With Cluster:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90        43\n",
            "           1       0.82      0.70      0.76        20\n",
            "\n",
            "    accuracy                           0.86        63\n",
            "   macro avg       0.85      0.82      0.83        63\n",
            "weighted avg       0.85      0.86      0.85        63\n",
            "\n",
            "Precisie: 0.823529\n",
            "Recall: 0.70\n",
            "AUC-PR: 0.792243\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKxD3Md6lPlvRS7jN83qvh"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}